val sales = spark.read.options(Map({"header" -> "True"},{"inferSchema" -> "true"})).csv("mnt/learningspark/home_data.csv")
sales.dtypes
sales.cache()
sales.show()
sales.printSchema()
import org.apache.spark.ml.feature.VectorAssembler
val sqft_living_assembler = new VectorAssembler().setInputCols(Array("sqft_living")).setOutputCol("features")
val sqft_living_df= sqft_living_assembler.transform(sales)
val Array(trainingData, testData) = sqft_living_df.randomSplit(Array(0.8, 0.2))
import org.apache.spark.ml.regression.LinearRegression
val sqft_living_lr  = new LinearRegression().setLabelCol("price").setFeaturesCol("features")
val sqft_living_lr_model = sqft_living_lr.fit(trainingData)
import org.apache.spark.ml.evaluation.RegressionEvaluator
val sqft_living_predictions = sqft_living_lr_model.transform(testData)
import org.apache.spark.sql.functions._
testData.select(mean("price").alias("price_value")).collect()
import org.apache.spark.ml.evaluation.RegressionEvaluator
val evaluator = new RegressionEvaluator()
  .setLabelCol("price")
  .setPredictionCol("prediction")
  .setMetricName("rmse")
val sqft_rmse = evaluator.evaluate(sqft_living_predictions)
println("Root Mean Squared Error (RMSE) on test data = " + sqft_rmse)
sales.select("bedrooms", "bathrooms", "sqft_living", "sqft_lot", "floors", "zipcode").show()
val my_features_assembler = new VectorAssembler().setInputCols(Array("bedrooms", "bathrooms", "sqft_living", "sqft_lot", "floors", "zipcode")).setOutputCol("features")
val my_features_df= my_features_assembler.transform(sales)
val Array(my_features_trainingData, my_features_testData) = my_features_df.randomSplit(Array(0.8, 0.2))
import org.apache.spark.ml.regression.LinearRegression
val my_features_lr  = new LinearRegression().setLabelCol("price").setFeaturesCol("features")
val my_features_model = my_features_lr.fit(my_features_trainingData)
val my_features_predictions = my_features_model.transform(my_features_testData)
my_features_predictions.select("prediction", "price", "features").show(5)
my_features_testData.select(mean("price").alias("price_value")).collect() 
val evaluator = new RegressionEvaluator()
  .setLabelCol("price")
  .setPredictionCol("prediction")
  .setMetricName("rmse")
val rmse = evaluator.evaluate(my_features_predictions)
println("Root Mean Squared Error (RMSE) on test data = " + rmse)
// MAGIC %md Pipeline
import org.apache.spark.ml.{Pipeline, PipelineModel}
val Array(my_features_trainingData, my_features_testData) = sales.randomSplit(Array(0.8, 0.2))
val my_features_assembler = new VectorAssembler().setInputCols(Array("bedrooms", "bathrooms", "sqft_living", "sqft_lot", "floors", "zipcode")).setOutputCol("features")
val my_features_lr  = new LinearRegression().setLabelCol("price").setFeaturesCol("features")
val pipeline = new Pipeline()
  .setStages(Array(my_features_assembler, my_features_lr))
val pipelineModel = pipeline.fit(my_features_trainingData)
val predictions_p = pipelineModel.transform(my_features_testData)
predictions_p.select("price", "prediction", "features").show()
val evaluator_p = new RegressionEvaluator()
  .setLabelCol("price")
  .setPredictionCol("prediction")
  .setMetricName("rmse")
val rmse_p = evaluator_p.evaluate(predictions_p)
println("Root Mean Squared Error (RMSE) on test data = " + rmse_p)
// MAGIC %md DecisionTreeRegressor
import org.apache.spark.ml.regression.DecisionTreeRegressionModel
import org.apache.spark.ml.regression.DecisionTreeRegressor
val dt = new DecisionTreeRegressor().setLabelCol("price").setFeaturesCol("features")
val pipeline_dt  = new Pipeline()
  .setStages(Array(my_features_assembler, dt))
val pipeline_dt_Model = pipeline_dt.fit(my_features_trainingData)
val predictions_dt= pipeline_dt_Model.transform(my_features_testData)
predictions_dt.select("price", "prediction", "features").show()
val rmse_dt = evaluator_p.evaluate(predictions_dt)
println("Root Mean Squared Error (RMSE) on test data = " + rmse_dt)
import org.apache.spark.ml.regression.{RandomForestRegressionModel, RandomForestRegressor}
val rf = new RandomForestRegressor().setLabelCol("price").setFeaturesCol("features")
val pipeline_rf  = new Pipeline()
  .setStages(Array(my_features_assembler, rf))
val pipeline_rf_Model = pipeline_rf.fit(my_features_trainingData)
val predictions_rf= pipeline_rf_Model.transform(my_features_testData)
predictions_dt.select("price", "prediction", "features").show()
val rmse_rf = evaluator_p.evaluate(predictions_rf)
println("Root Mean Squared Error (RMSE) on test data = " + rmse_rf)
// MAGIC %md Gradient-boosted tree regression
import org.apache.spark.ml.regression.{GBTRegressionModel, GBTRegressor}
val gbt = new GBTRegressor().setLabelCol("price").setFeaturesCol("features")
val pipeline_gbt  = new Pipeline()
  .setStages(Array(my_features_assembler, gbt))
val pipeline_gbt_Model = pipeline_gbt.fit(my_features_trainingData)
val predictions_gbt= pipeline_gbt_Model.transform(my_features_testData)
predictions_gbt.select("price", "prediction", "features").show()
val rmse_gbt = evaluator_p.evaluate(predictions_gbt)
println("Root Mean Squared Error (RMSE) on test data = " + rmse_gbt)
